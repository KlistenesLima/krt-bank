# ============================================================
# KRT Bank - Docker Compose Override for High-Load Testing
# Usage: docker-compose -f docker-compose.yml -f docker-compose.highload.yml up -d
# ============================================================
services:
  payments-api:
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 1G
        reservations:
          cpus: '1.0'
          memory: 512M
    environment:
      DOTNET_ThreadPool_MinThreads: 100
      ConnectionStrings__DefaultConnection: "Host=postgres;Port=5432;Database=krtbank;Username=krt;Password=${POSTGRES_PASSWORD};Pooling=true;MinPoolSize=20;MaxPoolSize=200;Connection Idle Lifetime=300"
      Redis__Configuration: "redis:6379,abortConnect=false,connectTimeout=5000,syncTimeout=5000"

  onboarding-api:
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 768M
        reservations:
          cpus: '0.5'
          memory: 256M
    environment:
      DOTNET_ThreadPool_MinThreads: 50
      ConnectionStrings__DefaultConnection: "Host=postgres;Port=5432;Database=krtbank;Username=krt;Password=${POSTGRES_PASSWORD};Pooling=true;MinPoolSize=10;MaxPoolSize=100"

  gateway:
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 512M
    environment:
      DOTNET_ThreadPool_MinThreads: 200

  postgres:
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
    command: >
      postgres
        -c max_connections=500
        -c shared_buffers=512MB
        -c effective_cache_size=1536MB
        -c maintenance_work_mem=128MB
        -c checkpoint_completion_target=0.9
        -c wal_buffers=16MB
        -c default_statistics_target=100
        -c random_page_cost=1.1
        -c effective_io_concurrency=200
        -c work_mem=4MB
        -c min_wal_size=1GB
        -c max_wal_size=4GB
        -c max_worker_processes=4
        -c max_parallel_workers_per_gather=2
        -c max_parallel_workers=4
        -c max_parallel_maintenance_workers=2
        -c log_min_duration_statement=200

  redis:
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
    command: >
      redis-server
        --maxmemory 256mb
        --maxmemory-policy allkeys-lru
        --tcp-backlog 511
        --timeout 0
        --tcp-keepalive 300

  kafka:
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
    environment:
      KAFKA_NUM_PARTITIONS: 12
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_NUM_IO_THREADS: 8
      KAFKA_NUM_NETWORK_THREADS: 5
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600

  rabbitmq:
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 1G

